\section{Discussion}
\justifying

This phase of the project focused on the two boot components that were both measurable and directly controllable across the full test matrix: the \textbf{Loader} and \textbf{Kernel} times reported by \texttt{systemd-analyze}. The experiments show that these phases can be improved through practical changes to the boot path and kernel configuration, but obviously a reduction in Loader or Kernel time does not automatically translate into a proportional reduction in \emph{total} boot time since firmware and userspace vary between runs or between system states. For this reason, the most defensible comparisons in this report are the stock-versus-optimized deltas within the same configuration, evaluated under the same cold-boot procedure which are for loader and kernel.\\

On native systems, the bootloader changes behaved as expected. Replacing GRUB with \texttt{systemd-boot} reduced pre-kernel overhead by simplifying the loader path and using minimal, explicit boot entries. This made the loader stage more direct and less variable, which aligns with the goal of improving the Loader phase without introducing additional moving parts. The UKI exploration fits into the same motivation—reducing complexity in the early boot path by packaging kernel and initramfs into a single EFI-loadable artifact—but it could not be carried through to the measurement campaign due to a hardware constraint: the primary USB device entered a persistent read-only state during experimentation. To preserve setup reliability and avoid misguided results, the measurement process recreated with exact same parameters except for the usb device itself which means the affected USB setup was recreated on a hardware-identical replacement device however eventhough it was retried several times same boot times were not achieved. Since project focus on improvements on kernel and loader time that goal was achieved on that setup too even if it was not the same control data used in Part1. \\

Kernel optimization was treated as a structured reduction and integration workflow rather than trial and error way. Candidates were grouped into categories (legacy hardware, unused networking subsystems, non-essential filesystems, debugging/tracing, virtualization features, and driver placement decisions), then filtered using dependency awareness and module-purpose validation. A 38 item candidatewas selected and assembled for native NVMe environments where early storage discovery is direct and the boot path is less fragile compared to usb setups. For native USB boots, the applied set had to be more carefully selected because the early boot path is sensitive to missing bridge drivers and filesystem support; several aggressive removals that are safe on NVMe can cause root discovery failures on USB. This is also why initramfs policy is discussed even though userspace is not a target: the initramfs directly mediates early device discovery and module availability, and overly aggressive minimization (e.g., \texttt{MODULES=dep} on USB) can omit essential drivers and lead to initramfs fallback behavior. Stabilizing USB boots therefore required retaining broader early-driver coverage while still applying safe kernel trimming.\\

Compression decisions were evaluated in the same early boot context. Transitioning from GZIP to LZ4 prioritized decompression speed, which is relevant when the kernel and initramfs payload has already been reduced through trimming. With a smaller artifact, the practical bottleneck shifts toward decompression latency and early CPU work, making faster decompression a reasonable choice for reducing perceived early boot wall-time. These decisions were validated empirically through repeated cold-boot trials rather than assumed. This part of the project higlights that, for USB boots in our setups, boot-time slowdowns were driven primarily by USB storage I/O throughput and latency, not by CPU performance or other subsystems such as networking or graphics.\\


Virtual machine results emphasize that kernel-time bottlenecks can be platform-specific and may not have a significant response to general trimming alone. In the Parallels ARM environment, a large portion of kernel time was explained by AHCI port probing behavior that is irrelevant in a virtualized setting but still triggered by the device model. Applying \texttt{libahci.ignore\_sss=1} directly addressed this root cause and produced the largest kernel-time reduction in that environment, while additional kernel trimming contributed a smaller secondary gain. This highlights an important lesson from the VM portion of the report: the highest-yield improvement can come from identifying a single dominant stall source in the kernel timeline and removing it, rather than uniformly minimizing features. Whether virtualization is used or not, it's important to trace kernel boot time to understand which steps are taking more time rather than blindly relying on reducing the kernel module set. Built-in kernels of Arch and Debian distributions on ARM were proven to be quite fast (in terms of boot performance) and most of the CPU time was being consumed by the staggered timeouts triggered by SSS signal. A more robust solution would require Parallels to update their AHCI controller to either stop propogating SSS signal or only introduce occupied SATA ports to guest OS. As long as Parallels AHCI Host sets HOST\_CAP\_SSS bit, compliant and modern kernels will scan devices with staggered spin-up.\\

Finally, the Debian NVMe results illustrate the limits of phase-focused optimization when the rest of the system is not held perfectly constant. Even when Loader time decreases strongly, increases in Kernel and/or userspace can dominate the end-to-end total. Since this project did not target userspace service optimization, these regressions are treated as outcomes to be explained rather than as evidence that the loader changes were ineffective. Overall, the report supports a practical conclusion: simplifying the bootloader path is a low-risk way to reduce Loader time, kernel trimming is effective when guided by dependency-aware selection and validated by cold-boot measurements, USB boots require conservative safety decisions to preserve early root discovery, and VM environments may require targeted kernel parameters to eliminate virtualization specific bottlenecks.
